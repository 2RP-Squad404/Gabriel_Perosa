# Relatório de Estudos

**Nome do Estagiário:** Gabriel Perosa  
**Data:** 14/08/2024

**Módulos/Etapas Feitas:**  
1. **Python**
2. **Apache Spark**
3. **PySpark**
4. **Apache Beam**
5. **Google Dataflow**
6. **Apache Airflow**

## Resumo dos módulos 

<h2>Linguagens e Frameworks</h2>

<h3>1. Python</h3>

A linguagem Python foi criada para facilitar o desenvolvimento, sendo conhecida pela simplicidade e facilidade de escrita, com linhas de códigos mais limpas e legíveis.

<h5>Os Principais benefícios do uso de Python </h5>

- Sintaxe simples
- Fácil interpretação
- Variedades de bibliotecas e frameworks

<h5>Principais bibliotecas</h5>

- Pandas: Biblioteca utilizada para manipulação de 
dados.

- NumPy: Biblioteca para tratamento de dados, oferece suporte para arrays multidimencionas.

- Django: Conjunto de bibliotecas para facilitar o desenvolvimento web.

- TensorFlow: Biblioteca voltada para criação de modelos de inteligência artificial.


Python é uma linguagem de alto nível, simplificada para facilitar o desenvolvimento de diversas aplicações como ciência de dados, aprendizado de máquina, desenvolvimento web, desenvolvimento de software. Uma linguagem muito versátil para diversas aplicações, se tornando muito popular, principalmente para quem esta ingressando na área de programação.<br>

<h3>2. Apache Spark</h3>
O Apache Spark é um framework com mecanismos que facilitam o processamento de dados, muito usado para grandes conjuntos de dados, tendo em vista que foi projetado para oferecer alta velocidade e escalabilidade.

<h3>3. PySpark</h3>
PySpark é uma ferramenta de processamento de dados, que foi desenvolvida com base na linguagem Python e no framework Spark, usada para agilizar a criação de softwares que envolvem grandes volumes de processamento de dados.

<h5>Os Principais benefícios do uso de PySpark </h5>

- Capacidade de processar dados em alta velocidade
- Suporte a varias linguagens
- Diversos usos de aplicações
- Facilidade no desenvolvimento

PySpark oferece uma vasta possibilidade para profissionais que trabalham com dados, tendo em vista a facilidade e velocidade para grandes volumes de dados. <br>

<h3>4. Apache Beam</h3>
Apache Beam é um modelo unificado, de código aberto para a criação de pipelines que podem ser usadas em diferentes sistemas, e possibilita usar diversas linguagens. O Apache Beam é essencial para analise e processamentos em tempo real. <br>

<h3>5. Google Dataflow</h3>
O Google Dataflow é um serviço de processamento de dados em tempo real e em lote, oferecido pelo Google Cloud Platform. Esse serviço facilita o processamento de grandes volumes de dados. O Dataflow utiliza o modelo de programação Apache Beam para processamento de dados.<br>

<h3>6. Apache Airflow</h3>
O Apache Airflow é uma ferramenta de orquestração de fluxo de trabalho de código aberto (open-source), a característica pricipal do Airflow é a sua capacidade de definir fluxos de trabalhos, e auxiliar no gerenciamento das tarefas.<br>





<br>

## Links de Laboratórios (se houver)

- [Google Colab 1/Notion 1](URL_do_Lab_1)
- [Google Colab 2/Notion 2](URL_do_Lab_2)
- ...

**Recursos Utilizados:**  
- [Recurso 1]
- [Recurso 2]
- [Recurso 3]
- ...

**Principais comandos: (se aplicável)**  
- [Comando 1]
- [Comando 2]
- [Comando 3]
- ...

**Desafios Encontrados:**  
Descreva quaisquer desafios ou obstáculos que você encontrou durante a trilha de aprendizagem e como você os superou ou planeja superá-los.

**Feedback e Ajustes:**  
Descreva qualquer feedback que você recebeu e como você ajustou sua abordagem de estudo com base nesse feedback.

**Próximos Passos:**  
Descreva os próximos passos em sua trilha de aprendizagem. Quais são as próximas etapas ou módulos que você irá abordar?